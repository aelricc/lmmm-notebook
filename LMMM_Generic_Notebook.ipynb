{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM5YB5PYkm3OTrQvn89iys2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aelricc/lmmm-notebook/blob/main/LMMM_Generic_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n",
        "You must run this first! (You can ignore the warnings, just a result of automatically restarting the runtime)"
      ],
      "metadata": {
        "id": "IgofgdutWBET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade git+https://github.com/google/lightweight_mmm.git\n",
        "!pip install -q xlrd\n",
        "!pip install fpdf2 matplotlib\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "XvYKYiesyZDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62385b38-d957-4a39-d22f-27362f1de661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/google/lightweight_mmm.git\n",
            "  Cloning https://github.com/google/lightweight_mmm.git to /tmp/pip-req-build-rwxmf49v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/lightweight_mmm.git /tmp/pip-req-build-rwxmf49v\n",
            "  Resolved https://github.com/google/lightweight_mmm.git to commit b4c99fa7532b767b7c3b519e41f8dffa15ab8c65\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (1.4.0)\n",
            "Requirement already satisfied: arviz>=0.11.2 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (0.15.1)\n",
            "Requirement already satisfied: immutabledict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (2.2.5)\n",
            "Requirement already satisfied: jax>=0.3.18 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (0.4.10)\n",
            "Requirement already satisfied: jaxlib>=0.3.18 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (0.4.10+cuda11.cudnn86)\n",
            "Requirement already satisfied: matplotlib==3.6.1 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (1.23.5)\n",
            "Requirement already satisfied: numpyro>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (0.12.1)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (1.10.1)\n",
            "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (0.11.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (1.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (0.13.5)\n",
            "Requirement already satisfied: tensorflow>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from lightweight-mmm==0.1.9) (2.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->lightweight-mmm==0.1.9) (2.8.2)\n",
            "Requirement already satisfied: setuptools>=60.0.0 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.2->lightweight-mmm==0.1.9) (67.7.2)\n",
            "Requirement already satisfied: xarray>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.2->lightweight-mmm==0.1.9) (2022.12.0)\n",
            "Requirement already satisfied: h5netcdf>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.2->lightweight-mmm==0.1.9) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.2->lightweight-mmm==0.1.9) (4.6.3)\n",
            "Requirement already satisfied: xarray-einstats>=0.3 in /usr/local/lib/python3.10/dist-packages (from arviz>=0.11.2->lightweight-mmm==0.1.9) (0.5.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.18->lightweight-mmm==0.1.9) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.18->lightweight-mmm==0.1.9) (3.3.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro>=0.9.2->lightweight-mmm==0.1.9) (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from numpyro>=0.9.2->lightweight-mmm==0.1.9) (4.65.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->lightweight-mmm==0.1.9) (2022.7.1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.0->lightweight-mmm==0.1.9) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (3.8.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (16.0.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.7.2->lightweight-mmm==0.1.9) (0.32.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightweight-mmm==0.1.9) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightweight-mmm==0.1.9) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.7.2->lightweight-mmm==0.1.9) (3.2.2)\n",
            "Requirement already satisfied: fpdf2 in /usr/local/lib/python3.10/dist-packages (2.7.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from fpdf2) (0.7.1)\n",
            "Requirement already satisfied: Pillow!=9.2.*,>=6.2.2 in /usr/local/lib/python3.10/dist-packages (from fpdf2) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from fpdf2) (4.40.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Data\n",
        "Make sure the data you want to input is\n",
        "\n",
        "1.   An .xlsx file\n",
        "2.   Stored in a folder called \"LMMM-Data\" on your Drive\n",
        "\n",
        "Don't forget to change the SEED!\n",
        "\n"
      ],
      "metadata": {
        "id": "TMDubEyvLF80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpyro\n",
        "#START HERE\n",
        "SEED = 100 #@param {type:\"raw\"}\n",
        "\n",
        "\n",
        "#You must have a folder called \"LMMM-Data\"\n",
        "file_name = \"data-simm5.xlsx\" #@param {type:\"string\"}\n",
        "sheet_name = 'Weekly'         #@param {type:\"string\"}\n",
        "\n",
        "#specify location of data\n",
        "media_data_names = \"impressions_YouTube impressions_Instagram clicks_Search\" #@param {type:\"string\"}\n",
        "spend_names = \"spend_YouTube spend_Instagram spend_Search\" #@param {type:\"string\"}\n",
        "target_names = \"total_revenue\" #@param {type:\"string\"}\n",
        "\n",
        "#extra features, holiday details, geos?\n",
        "other_feature_names = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#specify time range (leave blank for default, aka all dates)\n",
        "start_date = \"\" #@param {type:\"string\"}\n",
        "end_date = \"\"   #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#How much of the data do you want to test?\n",
        "test_size = 20 #@param {type:\"integer\"}\n",
        "\n",
        "#CHANGE THE SEED IF YOU'RE DOING A NEW TEST\n",
        "number_warmup=1000\n",
        "number_samples=1000\n",
        "degrees_seasonality=6\n",
        "\n",
        "weekly = True #@param {type: \"boolean\"}\n",
        "\n",
        "model_name = \"hill_adstock\" #@param [\"hill_adstock\", \"carryover\", \"adstock\"]\n",
        "\n",
        "default_priors = True #@param {type:\"boolean\"}\n",
        "\n",
        "if default_priors:\n",
        "  baseline_sales_contribution = 2\n",
        "\n",
        "  #hill-adstock\n",
        "  saturation_point = 1.\n",
        "  halfway_marginal_gains = 1.\n",
        "\n",
        "  #carryover\n",
        "  retention_rate_distribution = 1.\n",
        "  peak_effect_point = 1.\n",
        "else:\n",
        "  baseline_sales_contribution = 2 #@param {type:\"raw\"}\n",
        "\n",
        "  #hill-adstock\n",
        "  saturation_point = 1. #@param {type:\"raw\"}\n",
        "  halfway_marginal_gains = 1. #@param {type:\"raw\"}\n",
        "\n",
        "  #carryover\n",
        "  retention_rate_distribution = 1.  #@param {type:\"raw\"}\n",
        "  peak_effect_point = 1. #@param {type:\"raw\"}\n",
        "\n",
        "\n",
        "\n",
        "intercept = numpyro.distributions.HalfNormal(scale=baseline_sales_contribution)\n",
        "\n",
        "#hill-adstock\n",
        "K_rate = 1.\n",
        "half_max_effective_concentration = numpyro.distributions.Gamma(concentration=saturation_point, rate=K_rate)\n",
        "slope_rate = 1.\n",
        "slope = numpyro.distributions.Gamma(concentration=halfway_marginal_gains , rate=slope_rate)\n",
        "\n",
        "#carryover\n",
        "retentionrate_concentration_2 = 1.\n",
        "ad_effect_retention_rate = numpyro.distributions.Beta(concentration1=retention_rate_distribution, concentration0=retentionrate_concentration_2)\n",
        "peak_effect_delay = numpyro.distributions.HalfNormal(scale=peak_effect_point)\n",
        "\n",
        "#adstock\n",
        "\n",
        "lag_weight_concentration = 2  #@param {type:\"raw\"}\n",
        "lagweight_concentration_2 = 1. #@param {type:\"raw\"}\n",
        "\n",
        "lag_weight = numpyro.distributions.Beta(concentration1=lag_weight_concentration, concentration0=lagweight_concentration_2)\n",
        "\n"
      ],
      "metadata": {
        "id": "1DOiTGoZFaT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Model\n",
        "\n",
        "Output will be in a new folder in \"LMMM-Data\"\n",
        "\n",
        "(Here's mine) https://drive.google.com/drive/folders/11ciF7F-ut8rIhgwSgDNNp0UpY-jNIofT?usp=sharing"
      ],
      "metadata": {
        "id": "IM2PF6tTpQcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.internals.managers import ensure_wrapped_if_datetimelike\n",
        "#Importing data\n",
        "from lightweight_mmm import preprocessing, lightweight_mmm, plot, optimize_media\n",
        "import jax.numpy as jnp\n",
        "import numpyro\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path_to_file = '/content/drive/My Drive/LMMM-Data/' + file_name\n",
        "\n",
        "data = pd.read_excel(path_to_file, sheet_name) #SELECT DESIRED SHEET\n",
        "data_size = len(data)\n",
        "\n",
        "\n",
        "print(\"Original Data Set: \")\n",
        "print(data)\n",
        "\n",
        "\n",
        "media_data_cols = media_data_names.split()\n",
        "spend_cols = spend_names.split()\n",
        "target_cols = target_names.split()\n",
        "if other_feature_names: extra_feature_cols = other_feature_names.split()\n",
        "\n",
        "#divide dataframe into media data, target, and cost for use in model\n",
        "\n",
        "media_data = data.loc[:, media_data_cols]\n",
        "print(media_data_cols)\n",
        "print(media_data)\n",
        "\n",
        "target = data.loc[:,target_cols]\n",
        "costBS = data.loc[:, spend_cols]\n",
        "if other_feature_names: extra_features = data.loc[:, extra_feature_cols]\n",
        "\n",
        "\n",
        "if start_date and end_date:\n",
        "  media_data = media_data.loc[start_date:end_date,...]\n",
        "  target = target.loc[start_date:end_date,...]\n",
        "  costBS = costBS.loc[start_date:end_date,...]\n",
        "  if other_feature_names: extra_features = extra_features.loc[start_date:end_date,...]\n",
        "elif start_date and not end_date:\n",
        "  media_data = media_data.loc[start_date:,...]\n",
        "  target = target.loc[start_date:,...]\n",
        "  costBS = costBS.loc[start_date:,...]\n",
        "  if other_feature_names: extra_features = extra_features.loc[start_date:,...]\n",
        "elif not start_date and end_date:\n",
        "  media_data = media_data.loc[:end_date,...]\n",
        "  target = target.loc[:end_date,...]\n",
        "  costBS = costBS.loc[:end_date,...]\n",
        "  if other_feature_names: extra_features = extra_features.loc[:end_date,...]\n",
        "\n",
        "\n",
        "print(media_data)\n",
        "\n",
        "media_names = list(media_data.columns)\n",
        "#media_data.shape\n",
        "\n",
        "target = target.to_numpy().flatten()\n",
        "#target.shape\n",
        "\n",
        "unscaled_cost = costBS.sum().to_numpy()\n",
        "\n",
        "\n",
        "print(\"\\nMedia Data: \")\n",
        "print(media_data)\n",
        "\n",
        "print(\"\\nTarget Data: \")\n",
        "print(target)\n",
        "\n",
        "print(\"\\nSpend Data: \")\n",
        "print(unscaled_cost)\n",
        "\n",
        "\n",
        "#split data into training and testing data\n",
        "\n",
        "split_point = data_size - test_size\n",
        "\n",
        "media_data_train = (media_data.loc[:split_point, ...]).to_numpy()\n",
        "\n",
        "media_data_test = (media_data.loc[split_point:, ...]).to_numpy()\n",
        "\n",
        "target_train = (target[:(split_point+1)])\n",
        "target_test = target[(split_point):]\n",
        "\n",
        "if other_feature_names:\n",
        "  extra_features_train = (extra_features.loc[:split_point, ...]).to_numpy()\n",
        "  extra_features_test = (extra_features.loc[:split_point, ...]).to_numpy()\n",
        "\n",
        "\n",
        "#print(target_test)\n",
        "\n",
        "#scale the data\n",
        "\n",
        "media_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "target_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "cost_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean, multiply_by=1)\n",
        "\n",
        "media_data_train = media_scaler.fit_transform(media_data_train)\n",
        "target_train = target_scaler.fit_transform(target_train)\n",
        "costs = cost_scaler.fit_transform(unscaled_cost)\n",
        "if other_feature_names: extra_features_train = target_scaler.fit_transform(extra_features_train)\n",
        "\n",
        "print(costs)\n",
        "\n",
        "'''\n",
        "print(media_data_train)\n",
        "print(target_train)\n",
        "'''\n",
        "\n",
        "#run this to make sure data has been preprocessed appropiately\n",
        "correlations, variances, spend_fractions, variance_inflation_factors = preprocessing.check_data_quality(\n",
        "    media_data=media_scaler.transform(media_data),\n",
        "    target_data=target_scaler.transform(target),\n",
        "    cost_data=costs)\n",
        "correlations[0].style.background_gradient(cmap='RdBu', vmin=-1, vmax=1).set_precision(3)\n",
        "def highlight_variances(x: float,\n",
        "                        low_variance_threshold: float=1.0e-3,\n",
        "                        high_variance_threshold: float=3.0) -> str:\n",
        "\n",
        "    if x < low_variance_threshold or x > high_variance_threshold:\n",
        "      weight = 'bold'\n",
        "      color = 'red'\n",
        "    else:\n",
        "      weight = 'normal'\n",
        "      color = 'black'\n",
        "    style = f'font-weight: {weight}; color: {color}'\n",
        "    return style\n",
        "\n",
        "variances.style.set_precision(4).applymap(highlight_variances)\n",
        "def highlight_low_spend_fractions(x: float,\n",
        "                                  low_spend_threshold: float=0.01) -> str:\n",
        "    if x < low_spend_threshold:\n",
        "      weight = 'bold'\n",
        "      color = 'red'\n",
        "    else:\n",
        "      weight = 'normal'\n",
        "      color = 'black'\n",
        "    style = f'font-weight: {weight}; color: {color}'\n",
        "    return style\n",
        "\n",
        "spend_fractions.style.set_precision(4).applymap(highlight_low_spend_fractions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "code",
        "id": "G4vQso5Upi1Y",
        "outputId": "02632ea8-1093-49f9-871c-d2bc0fd3910b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Original Data Set: \n",
            "          DATE  impressions_YouTube  impressions_Instagram  spend_YouTube  \\\n",
            "0   2019-01-01         1.413640e+08           1.478478e+07  424251.295187   \n",
            "1   2019-01-08         1.574656e+08           1.596988e+07  473207.183662   \n",
            "2   2019-01-15         1.317644e+08           1.606780e+07  395621.056817   \n",
            "3   2019-01-22         1.303690e+08           1.324150e+07  390489.494772   \n",
            "4   2019-01-29         1.473974e+08           1.658058e+07  441941.250186   \n",
            "..         ...                  ...                    ...            ...   \n",
            "99  2020-11-24         1.262730e+08           1.380767e+07  378768.830841   \n",
            "100 2020-12-01         1.308056e+08           1.431418e+07  392754.639475   \n",
            "101 2020-12-08         1.179249e+08           1.302560e+07  353510.212512   \n",
            "102 2020-12-15         1.333239e+08           1.552973e+07  400570.325299   \n",
            "103 2020-12-22         1.242302e+08           1.217475e+07  372511.789478   \n",
            "\n",
            "     spend_Instagram  clicks_Search  spend_Search  total_revenue  \n",
            "0      297316.068882   6.642815e+06  1.721914e+06   2.258534e+07  \n",
            "1      320213.367574   7.734409e+06  1.925091e+06   2.556265e+07  \n",
            "2      322417.309546   6.343492e+06  1.647076e+06   2.208320e+07  \n",
            "3      264812.139059   6.096665e+06  1.614910e+06   2.239866e+07  \n",
            "4      333022.664971   7.172531e+06  1.868049e+06   2.441775e+07  \n",
            "..               ...            ...           ...            ...  \n",
            "99     277150.163111   5.737404e+06  1.505760e+06   3.038186e+07  \n",
            "100    285951.974041   6.295855e+06  1.610739e+06   3.195538e+07  \n",
            "101    261037.913849   5.660241e+06  1.454507e+06   2.973084e+07  \n",
            "102    310419.186778   6.371797e+06  1.646078e+06   3.220107e+07  \n",
            "103    244160.715707   5.867944e+06  1.519694e+06   3.027843e+07  \n",
            "\n",
            "[104 rows x 8 columns]\n",
            "['impressions_YouTube', 'impressions_Instagram', 'clicks_Search']\n",
            "     impressions_YouTube  impressions_Instagram  clicks_Search\n",
            "0           1.413640e+08           1.478478e+07   6.642815e+06\n",
            "1           1.574656e+08           1.596988e+07   7.734409e+06\n",
            "2           1.317644e+08           1.606780e+07   6.343492e+06\n",
            "3           1.303690e+08           1.324150e+07   6.096665e+06\n",
            "4           1.473974e+08           1.658058e+07   7.172531e+06\n",
            "..                   ...                    ...            ...\n",
            "99          1.262730e+08           1.380767e+07   5.737404e+06\n",
            "100         1.308056e+08           1.431418e+07   6.295855e+06\n",
            "101         1.179249e+08           1.302560e+07   5.660241e+06\n",
            "102         1.333239e+08           1.552973e+07   6.371797e+06\n",
            "103         1.242302e+08           1.217475e+07   5.867944e+06\n",
            "\n",
            "[104 rows x 3 columns]\n",
            "     impressions_YouTube  impressions_Instagram  clicks_Search\n",
            "0           1.413640e+08           1.478478e+07   6.642815e+06\n",
            "1           1.574656e+08           1.596988e+07   7.734409e+06\n",
            "2           1.317644e+08           1.606780e+07   6.343492e+06\n",
            "3           1.303690e+08           1.324150e+07   6.096665e+06\n",
            "4           1.473974e+08           1.658058e+07   7.172531e+06\n",
            "..                   ...                    ...            ...\n",
            "99          1.262730e+08           1.380767e+07   5.737404e+06\n",
            "100         1.308056e+08           1.431418e+07   6.295855e+06\n",
            "101         1.179249e+08           1.302560e+07   5.660241e+06\n",
            "102         1.333239e+08           1.552973e+07   6.371797e+06\n",
            "103         1.242302e+08           1.217475e+07   5.867944e+06\n",
            "\n",
            "[104 rows x 3 columns]\n",
            "\n",
            "Media Data: \n",
            "     impressions_YouTube  impressions_Instagram  clicks_Search\n",
            "0           1.413640e+08           1.478478e+07   6.642815e+06\n",
            "1           1.574656e+08           1.596988e+07   7.734409e+06\n",
            "2           1.317644e+08           1.606780e+07   6.343492e+06\n",
            "3           1.303690e+08           1.324150e+07   6.096665e+06\n",
            "4           1.473974e+08           1.658058e+07   7.172531e+06\n",
            "..                   ...                    ...            ...\n",
            "99          1.262730e+08           1.380767e+07   5.737404e+06\n",
            "100         1.308056e+08           1.431418e+07   6.295855e+06\n",
            "101         1.179249e+08           1.302560e+07   5.660241e+06\n",
            "102         1.333239e+08           1.552973e+07   6.371797e+06\n",
            "103         1.242302e+08           1.217475e+07   5.867944e+06\n",
            "\n",
            "[104 rows x 3 columns]\n",
            "\n",
            "Target Data: \n",
            "[22585337.72983767 25562650.31605433 22083203.57663519 22398657.12257738\n",
            " 24417749.46375804 24170799.74965269 19620279.63100591 25732100.20496768\n",
            " 24548431.22907869 23539764.42061143 26946866.20296828 23900864.91568796\n",
            " 28504940.78034762 21855006.30048055 25480146.49860342 24459337.23443004\n",
            " 21898928.25745214 25327475.23464796 23954609.82447682 22410637.6677781\n",
            " 20161261.78234639 23184576.11492906 19121734.83410756 22905707.21934642\n",
            " 22763036.18314814 22877264.14304784 22392188.86160474 25429285.78006757\n",
            " 21304225.91755642 19275495.70243116 22067252.2943374  23195644.01311694\n",
            " 20419242.55168674 23086026.26287356 27336690.58790478 25502375.97353718\n",
            " 25217073.60177636 22958234.40265541 26817462.05197192 27993454.98012304\n",
            " 22401114.61630727 28102926.59675196 27444460.42007188 33091232.68218496\n",
            " 24140435.81409026 27343559.33241926 30805419.69697079 24861094.28705478\n",
            " 22899054.24309615 25542689.54783258 28715734.67010822 30365618.14968724\n",
            " 27553779.16604326 28929661.35292829 28753241.6898525  30240443.36274774\n",
            " 33560142.18017715 27427578.00538938 29011557.39015921 25006364.42659388\n",
            " 22343110.83661509 25881219.22245225 29720833.88311435 26047218.13501808\n",
            " 27848355.19616741 32404474.41421627 28501459.82786305 31478230.7009207\n",
            " 28140700.04633639 30811949.23242994 28599013.57473255 27281312.05565331\n",
            " 26646273.57219403 28953587.29540053 32825526.05219751 29528427.61616161\n",
            " 29361031.96901604 36262345.11116198 30718495.81354297 27369416.02138979\n",
            " 26920055.03432686 32785770.50846419 25268519.95094075 28763140.89023026\n",
            " 31981516.10974072 31238391.59069873 29403170.81873794 30198573.46829167\n",
            " 31475515.58238504 35093752.12247789 28292315.97012242 29592543.77932906\n",
            " 31129865.14581868 30600370.35289079 34720413.37283804 31169665.83510145\n",
            " 31552500.92947805 25330772.99229523 32754893.06996126 30381860.04217615\n",
            " 31955378.76341088 29730837.98901211 32201069.32090631 30278427.77735165]\n",
            "\n",
            "Spend Data: \n",
            "[4.18197118e+07 2.99467066e+07 1.68604652e+08]\n",
            "[0.5219394  0.37375593 2.1043046 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-704d06566037>:118: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
            "  correlations[0].style.background_gradient(cmap='RdBu', vmin=-1, vmax=1).set_precision(3)\n",
            "<ipython-input-37-704d06566037>:132: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
            "  variances.style.set_precision(4).applymap(highlight_variances)\n",
            "<ipython-input-37-704d06566037>:144: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
            "  spend_fractions.style.set_precision(4).applymap(highlight_low_spend_fractions)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f50d7ce1120>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5ca86_row0_col0, #T_5ca86_row1_col0, #T_5ca86_row2_col0 {\n",
              "  font-weight: normal;\n",
              "  color: black;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5ca86\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_5ca86_level0_col0\" class=\"col_heading level0 col0\" >fraction of spend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5ca86_level0_row0\" class=\"row_heading level0 row0\" >feature_0</th>\n",
              "      <td id=\"T_5ca86_row0_col0\" class=\"data row0 col0\" >0.1740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5ca86_level0_row1\" class=\"row_heading level0 row1\" >feature_1</th>\n",
              "      <td id=\"T_5ca86_row1_col0\" class=\"data row1 col0\" >0.1246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5ca86_level0_row2\" class=\"row_heading level0 row2\" >feature_2</th>\n",
              "      <td id=\"T_5ca86_row2_col0\" class=\"data row2 col0\" >0.7014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameterdict = {}\n",
        "\n",
        "if model_name == \"hill_adstock\":\n",
        "  custom_priors= {\n",
        "      \"intercept\": intercept,\n",
        "      \"half_max_effective_concentration\": half_max_effective_concentration,\n",
        "      \"slope\": slope\n",
        "      }\n",
        "  for i in ('baseline_sales_contribution', 'saturation_point', 'halfway_marginal_gains'):\n",
        "      parameterdict[i] = locals()[i]\n",
        "\n",
        "elif model_name == \"carryover\":\n",
        "  custom_priors= {\n",
        "    \"intercept\": intercept,\n",
        "    \"ad_effect_retention_rate\": ad_effect_retention_rate,\n",
        "    \"peak_effect_delay\": peak_effect_delay\n",
        "    }\n",
        "  for i in ('baseline_sales_contribution', 'retention_rate_distribution', 'peak_effect_point'):\n",
        "      parameterdict[i] = locals()[i]\n",
        "\n",
        "elif model_name == \"adstock\":\n",
        "  custom_priors= {\n",
        "    \"intercept\": intercept,\n",
        "    \"lag_weight\": lag_weight,\n",
        "    }\n",
        "  for i in ('baseline_sales_contribution', 'lag_weight_concentration', 'lagweight_concentration_2'):\n",
        "    parameterdict[i] = locals()[i]\n",
        "\n",
        "if weekly is True:\n",
        "  weekday_seasonality=False\n",
        "  seasonality_frequency=52\n",
        "else:\n",
        "  weekday_seasonality=True\n",
        "  seasonality_frequency=365\n",
        "\n",
        "media_prior = costs\n",
        "\n",
        "\n",
        "mmm = lightweight_mmm.LightweightMMM(model_name)\n",
        "\n",
        "if other_feature_names:\n",
        "  mmm.fit(\n",
        "      media=media_data_train,\n",
        "      media_names=media_names,\n",
        "      media_prior=media_prior,\n",
        "      target=target_train,\n",
        "      extra_features=extra_features_train,\n",
        "      number_warmup=number_warmup,\n",
        "      number_samples=number_samples,\n",
        "      degrees_seasonality=degrees_seasonality,\n",
        "      weekday_seasonality=weekday_seasonality,\n",
        "      seasonality_frequency=seasonality_frequency,\n",
        "      custom_priors = custom_priors,\n",
        "      seed = SEED)\n",
        "else:\n",
        "  mmm.fit(\n",
        "      media=media_data_train,\n",
        "      media_names=media_names,\n",
        "      media_prior=media_prior,\n",
        "      target=target_train,\n",
        "      number_warmup=number_warmup,\n",
        "      number_samples=number_samples,\n",
        "      degrees_seasonality=degrees_seasonality,\n",
        "      weekday_seasonality=weekday_seasonality,\n",
        "      seasonality_frequency=seasonality_frequency,\n",
        "      custom_priors = custom_priors,\n",
        "      seed = SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I2yJ1Ceuy0W",
        "outputId": "c14645e7-a041-405e-bad9-19978260d4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightweight_mmm/lightweight_mmm.py:358: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
            "  mcmc = numpyro.infer.MCMC(\n",
            "sample: 100%|██████████| 2000/2000 [01:04<00:00, 30.78it/s, 1023 steps of size 3.67e-03. acc. prob=0.92]\n",
            "sample: 100%|██████████| 2000/2000 [01:07<00:00, 29.46it/s, 1023 steps of size 2.75e-03. acc. prob=0.94]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import lightweight_mmm.utils as utils\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "from fpdf import FPDF\n",
        "import matplotlib\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "import seaborn as sns\n",
        "from typing import Any, List, Optional, Sequence, Tuple\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt1 = plot.plot_model_fit(mmm, target_scaler=target_scaler)\n",
        "\n",
        "directory = file_name + '-' + str(SEED) + '-result'\n",
        "parent_dir = \"/content/drive/My Drive/LMMM-Data/\"\n",
        "\n",
        "path = os.path.join(parent_dir, directory)\n",
        "\n",
        "if not os.path.exists(path):\n",
        "  os.mkdir(path)\n",
        "\n",
        "plt1.savefig(path + '/model_fit.pdf')\n",
        "\n",
        "new_predictions = mmm.predict(media=media_scaler.transform(media_data_test),\n",
        "                              seed=SEED)\n",
        "\n",
        "plt2 = plot.plot_out_of_sample_model_fit(out_of_sample_predictions=new_predictions,\n",
        "                                 out_of_sample_target=target_scaler.transform(target[split_point:]))\n",
        "plt2.savefig(path + '/OOS_model_fit.pdf')\n",
        "\n",
        "plt3 = plot.plot_media_channel_posteriors(media_mix_model=mmm, channel_names = media_names)\n",
        "plt3.savefig(path + '/media_channel_posteriors.pdf')\n",
        "\n",
        "#plt4 = plot.plot_prior_and_posterior(media_mix_model=mmm)\n",
        "#plt4.savefig(path + '/prior_and_posterior.pdf')\n",
        "\n",
        "media_contribution, roi_hat = mmm.get_posterior_metrics(target_scaler=target_scaler, cost_scaler=cost_scaler)\n",
        "\n",
        "plt5 = plot.plot_media_baseline_contribution_area_plot(media_mix_model=mmm,\n",
        "                                                target_scaler=target_scaler,\n",
        "                                                channel_names = media_names,\n",
        "                                                fig_size=(30,10))\n",
        "plt5.savefig(path + '/media_baseline_contribution_area.pdf')\n"
      ],
      "metadata": {
        "id": "M2zfxk-YVx0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf505616-ce7f-475e-b5d5-1fdd682ae457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py:509: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"stats_variance_1d\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at /usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py (511)\n",
            "\n",
            "File \"../usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py\", line 511:\n",
            "def stats_variance_1d(data, ddof=0):\n",
            "    a_a, b_b = 0, 0\n",
            "    ^\n",
            "\n",
            "  @conditional_jit\n",
            "/usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py:509: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"stats_variance_1d\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"../usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py\", line 512:\n",
            "def stats_variance_1d(data, ddof=0):\n",
            "    <source elided>\n",
            "    a_a, b_b = 0, 0\n",
            "    for i in data:\n",
            "    ^\n",
            "\n",
            "  @conditional_jit\n",
            "/usr/local/lib/python3.10/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"stats_variance_1d\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"../usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py\", line 511:\n",
            "def stats_variance_1d(data, ddof=0):\n",
            "    a_a, b_b = 0, 0\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.10/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"../usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py\", line 511:\n",
            "def stats_variance_1d(data, ddof=0):\n",
            "    a_a, b_b = 0, 0\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
            "/usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py:509: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"stats_variance_1d\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at /usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py (512)\n",
            "\n",
            "File \"../usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py\", line 512:\n",
            "def stats_variance_1d(data, ddof=0):\n",
            "    <source elided>\n",
            "    a_a, b_b = 0, 0\n",
            "    for i in data:\n",
            "    ^\n",
            "\n",
            "  @conditional_jit\n",
            "/usr/local/lib/python3.10/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"stats_variance_1d\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"../usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py\", line 512:\n",
            "def stats_variance_1d(data, ddof=0):\n",
            "    <source elided>\n",
            "    a_a, b_b = 0, 0\n",
            "    for i in data:\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.10/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"../usr/local/lib/python3.10/dist-packages/arviz/stats/stats_utils.py\", line 512:\n",
            "def stats_variance_1d(data, ddof=0):\n",
            "    <source elided>\n",
            "    a_a, b_b = 0, 0\n",
            "    for i in data:\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bars_media_metrics_fixed(\n",
        "    metric: jnp.ndarray,\n",
        "    metric_name: str = \"metric\",\n",
        "    channel_names: Optional[Tuple[Any]] = None,\n",
        "    interval_mid_range: float = .9) -> matplotlib.figure.Figure:\n",
        "\n",
        "  if channel_names is None:\n",
        "    channel_names = np.arange(np.shape(metric)[1])\n",
        "  upper_quantile = 1 - (1 - interval_mid_range) / 2\n",
        "  lower_quantile = (1 - interval_mid_range) / 2\n",
        "\n",
        "  if metric.ndim == 3:\n",
        "    metric = jnp.mean(metric, axis=-1)\n",
        "\n",
        "  if (metric_name == \"Media Contribution Percentage\"):\n",
        "    metric = metric*(100)\n",
        "\n",
        "\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "  sns.barplot(data=metric, ci=None, ax=ax, orient='h')\n",
        "  quantile_bounds = np.quantile(\n",
        "      metric, q=[lower_quantile, upper_quantile], axis=0)\n",
        "  quantile_bounds[0] = metric.mean(axis=0) - quantile_bounds[0]\n",
        "  quantile_bounds[1] = quantile_bounds[1] - metric.mean(axis=0)\n",
        "\n",
        "  if (metric_name == \"Media Contribution Percentage\"):\n",
        "      ax.bar_label(ax.containers[0], fmt='%.2f%%')\n",
        "  else:\n",
        "      ax.bar_label(ax.containers[0])\n",
        "  ax.set_yticks(range(len(channel_names)))\n",
        "  ax.set_yticklabels(channel_names, rotation=0)\n",
        "  fig.suptitle(\n",
        "      f\"Estimated media channel {metric_name}.\"\n",
        "  )\n",
        "  plt.tight_layout()\n",
        "  plt.close()\n",
        "  return fig\n",
        "\n",
        "\n",
        "plt6 = plot_bars_media_metrics_fixed(metric=media_contribution, channel_names = media_names, metric_name=\"Media Contribution Percentage\")\n",
        "#plt6.set_figheight(10)\n",
        "plt6.savefig(path + '/media_contribution_percentage.pdf')\n",
        "\n",
        "plt10 = plot_bars_media_metrics_fixed(metric=costs, channel_names = media_names, metric_name=\"Spend Data\")\n",
        "\n",
        "\n",
        "plt7 = plot_bars_media_metrics_fixed(metric=roi_hat, channel_names = media_names, metric_name=\"ROI hat\")\n",
        "#plt7.set_figheight(10)\n",
        "plt7.savefig(path + '/roi-hat.pdf')\n",
        "\n",
        "\n",
        "\n",
        "plt8 = plot.plot_response_curves(media_mix_model=mmm, target_scaler=target_scaler, seed=SEED)\n",
        "plt8.savefig(path + '/response_curves.pdf')\n",
        "\n",
        "file_path = path + '/' + directory + \".pkl\"\n",
        "utils.save_model(media_mix_model=mmm, file_path=file_path)\n",
        "\n",
        "contribution_df = plot.create_media_baseline_contribution_df(media_mix_model=mmm, target_scaler=target_scaler, channel_names = media_names)\n",
        "contribution_df.to_excel(path + '/media_baseline_contribution.xlsx')\n",
        "\n",
        "figs = [plt1, plt2, plt5, plt6, plt7, plt8]\n"
      ],
      "metadata": {
        "id": "URZNGbgrtocO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = FPDF()\n",
        "pdf.set_font('helvetica', size=14)\n",
        "\n",
        "if not other_feature_names: other_feature_names = \"None\"\n",
        "pdf.add_page()\n",
        "pdf.multi_cell(w = 0, h = 5,\n",
        "               txt = \"File Name: \" + file_name + \"\\n\\n\"\n",
        "                   + \"Model Name: \" + model_name + \"\\n\\n\"\n",
        "                   + \"Media Channels: \" + ', '.join([str(elem) for elem in media_names]) + \"\\n\\n\"\n",
        "                   + \"Extra Features: \"  + other_feature_names + \"\\n\"\n",
        "               )\n",
        "if(media_priors)\n",
        "if not default_priors:\n",
        "  pdf.write(txt=\"Custom Priors: \\n\")\n",
        "  for x in parameterdict:\n",
        "    pdf.write(txt= x + ': '+ str(parameterdict[x]) + \"\\n\")\n",
        "else:\n",
        "  pdf.write(txt=\"Default Priors \\n\")\n",
        "\n",
        "pdf.set_font('helvetica', size=14, style=\"B\")\n",
        "pdf.add_page()\n",
        "canvas = FigureCanvas(plt1)\n",
        "canvas.draw()\n",
        "img = Image.fromarray(np.asarray(canvas.buffer_rgba()))\n",
        "\n",
        "pdf.cell(w=0, h=5, txt=\"Model Fit on Training Data, \" + str(split_point) + \" weeks\", align=\"C\")\n",
        "pdf.image(img, w=pdf.epw, x=10, y = 15)  # Make the image full width\n",
        "\n",
        "canvas = FigureCanvas(plt2)\n",
        "canvas.draw()\n",
        "img = Image.fromarray(np.asarray(canvas.buffer_rgba()))\n",
        "pdf.set_y(y=155)\n",
        "pdf.cell(w=0, h=5, txt=\"Model Fit on Testing Data, \" + str(test_size) + \" weeks\", align=\"C\")\n",
        "pdf.image(img, w=pdf.epw, x=10,y=160)  # Make the image full width\n",
        "\n",
        "pdf.add_page()\n",
        "canvas = FigureCanvas(plt10)\n",
        "canvas.draw()\n",
        "img = Image.fromarray(np.asarray(canvas.buffer_rgba()))\n",
        "pdf.image(img, w=125, x=10,y=5)\n",
        "\n",
        "canvas = FigureCanvas(plt6)\n",
        "canvas.draw()\n",
        "img = Image.fromarray(np.asarray(canvas.buffer_rgba()))\n",
        "pdf.image(img, w=125, x=10,y=100)  # Make the image full width\n",
        "\n",
        "#pdf.add_page()\n",
        "canvas = FigureCanvas(plt7)\n",
        "canvas.draw()\n",
        "img = Image.fromarray(np.asarray(canvas.buffer_rgba()))\n",
        "pdf.image(img, w=125, x=10,y=195)  # Make the image full width\n",
        "\n",
        "pdf.add_page()\n",
        "canvas = FigureCanvas(plt8)\n",
        "canvas.draw()\n",
        "img = Image.fromarray(np.asarray(canvas.buffer_rgba()))\n",
        "pdf.image(img, w=pdf.epw, x=10,y=15)  # Make the image full width\n",
        "\n",
        "pdf.output(path + model_name + \"matplotlib.pdf\")"
      ],
      "metadata": {
        "id": "8WzGK1Fu2QOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_stdout = sys.stdout # Save a reference to the original standard output\n",
        "text = '/content/drive/My Drive/LMMM-Data/' + directory + '/summary.txt'\n",
        "with open(text ,'w') as f :\n",
        "  sys.stdout = f # Change the standard output to the file we created.\n",
        "  print(\"Model Name: \" + model_name)\n",
        "  print(\"Media Channels: \" + ', '.join([str(elem) for elem in media_names]))\n",
        "  print(\"Number of warmups: \" + str(number_warmup))\n",
        "  print(\"Number of samples: \" + str(number_samples))\n",
        "  print(\"Degrees of seasonality: \" + str(degrees_seasonality))\n",
        "  print(\"Custom priors: \" + str(custom_priors))\n",
        "  mmm.print_summary()\n",
        "  sys.stdout = original_stdout"
      ],
      "metadata": {
        "id": "XrEGM246o2Rs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}